package handler

// * +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
// * Copyright 2023 The Geek-AI Authors. All rights reserved.
// * Use of this source code is governed by a Apache-2.0 license
// * that can be found in the LICENSE file.
// * @Author yangjian102621@163.com
// * +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

import (
	"bytes"
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"geekai/core"
	"geekai/core/types"
	"geekai/service"
	"geekai/service/oss"
	"geekai/store/model"
	"geekai/store/vo"
	"geekai/utils"
	"geekai/utils/resp"
	"io"
	"net/http"
	"net/url"
	"os"
	"path"
	"strings"
	"time"
	"unicode/utf8"

	"github.com/gin-gonic/gin"
	"github.com/go-redis/redis/v8"
	"github.com/sashabaranov/go-openai"
	"gorm.io/gorm"
)

const (
	ChatEventStart        = "start"
	ChatEventEnd          = "end"
	ChatEventError        = "error"
	ChatEventMessageDelta = "message_delta"
	ChatEventTitle        = "title"
)

type ChatInput struct {
	UserId    uint            `json:"user_id"`
	RoleId    uint            `json:"role_id"`
	ModelId   uint            `json:"model_id"`
	ChatId    string          `json:"chat_id"`
	Prompt    string          `json:"prompt"`
	Tools     []uint          `json:"tools"`
	Stream    bool            `json:"stream"`
	Files     []vo.File       `json:"files"`
	ChatModel model.ChatModel `json:"chat_model,omitempty"`
	ChatRole  model.ChatRole  `json:"chat_role,omitempty"`
	LastMsgId uint            `json:"last_msg_id,omitempty"` // æœ€åçš„æ¶ˆæ¯IDï¼Œç”¨äºé‡æ–°ç”Ÿæˆç­”æ¡ˆçš„æ—¶å€™è¿‡æ»¤ä¸Šä¸‹æ–‡
}

type ChatHandler struct {
	BaseHandler
	redis          *redis.Client
	uploadManager  *oss.UploaderManager
	licenseService *service.LicenseService
	ReqCancelFunc  *types.LMap[string, context.CancelFunc] // HttpClient è¯·æ±‚å–æ¶ˆ handle function
	ChatContexts   *types.LMap[string, []any]              // èŠå¤©ä¸Šä¸‹æ–‡ Map [chatId] => []Message
	userService    *service.UserService
}

func NewChatHandler(app *core.AppServer, db *gorm.DB, redis *redis.Client, manager *oss.UploaderManager, licenseService *service.LicenseService, userService *service.UserService) *ChatHandler {
	return &ChatHandler{
		BaseHandler:    BaseHandler{App: app, DB: db},
		redis:          redis,
		uploadManager:  manager,
		licenseService: licenseService,
		ReqCancelFunc:  types.NewLMap[string, context.CancelFunc](),
		ChatContexts:   types.NewLMap[string, []any](),
		userService:    userService,
	}
}

// Chat å¤„ç†èŠå¤©è¯·æ±‚
func (h *ChatHandler) Chat(c *gin.Context) {
	var input ChatInput
	if err := c.ShouldBindJSON(&input); err != nil {
		resp.ERROR(c, types.InvalidArgs)
		return
	}

	// è®¾ç½®SSEå“åº”å¤´
	c.Header("Prompt-Type", "text/event-stream")
	c.Header("Cache-Control", "no-cache")
	c.Header("Connection", "keep-alive")
	c.Header("X-Accel-Buffering", "no")

	ctx, cancel := context.WithCancel(c.Request.Context())
	defer cancel()

	// ä½¿ç”¨æ—§çš„èŠå¤©æ•°æ®è¦†ç›–æ¨¡å‹å’Œè§’è‰²ID
	var chat model.ChatItem
	h.DB.Where("chat_id", input.ChatId).First(&chat)
	if chat.Id > 0 {
		input.ModelId = chat.ModelId
		input.RoleId = chat.RoleId
	}

	// éªŒè¯èŠå¤©è§’è‰²
	var chatRole model.ChatRole
	err := h.DB.First(&chatRole, input.RoleId).Error
	if err != nil || !chatRole.Enable {
		pushMessage(c, ChatEventError, "å½“å‰èŠå¤©è§’è‰²ä¸å­˜åœ¨æˆ–è€…æœªå¯ç”¨ï¼Œè¯·æ›´æ¢è§’è‰²ä¹‹åå†å‘èµ·å¯¹è¯ï¼")
		return
	}
	input.ChatRole = chatRole

	// è·å–æ¨¡å‹ä¿¡æ¯
	var chatModel model.ChatModel
	err = h.DB.Where("id", input.ModelId).First(&chatModel).Error
	if err != nil || !chatModel.Enabled {
		pushMessage(c, ChatEventError, "å½“å‰AIæ¨¡å‹æš‚æœªå¯ç”¨ï¼Œè¯·æ›´æ¢æ¨¡å‹åå†å‘èµ·å¯¹è¯ï¼")
		return
	}
	input.ChatModel = chatModel

	// å‘é€æ¶ˆæ¯
	err = h.sendMessage(ctx, input, c)
	if err != nil {
		pushMessage(c, ChatEventError, err.Error())
		return
	}

	pushMessage(c, ChatEventEnd, "å¯¹è¯å®Œæˆ")
}

func pushMessage(c *gin.Context, msgType string, content interface{}) {
	c.SSEvent("message", map[string]interface{}{
		"type": msgType,
		"body": content,
	})
	c.Writer.Flush()
}

func (h *ChatHandler) sendMessage(ctx context.Context, input ChatInput, c *gin.Context) error {
	var user model.User
	res := h.DB.Model(&model.User{}).First(&user, input.UserId)
	if res.Error != nil {
		return errors.New("æœªæˆæƒç”¨æˆ·ï¼Œæ‚¨æ­£åœ¨è¿›è¡Œéæ³•æ“ä½œï¼")
	}
	var userVo vo.User
	err := utils.CopyObject(user, &userVo)
	userVo.Id = user.Id
	if err != nil {
		return errors.New("User å¯¹è±¡è½¬æ¢å¤±è´¥ï¼Œ" + err.Error())
	}

	if !userVo.Status {
		return errors.New("æ‚¨çš„è´¦å·å·²ç»è¢«ç¦ç”¨ï¼Œå¦‚æœç–‘é—®ï¼Œè¯·è”ç³»ç®¡ç†å‘˜ï¼")
	}

	if userVo.Power < input.ChatModel.Power {
		return fmt.Errorf("æ‚¨å½“å‰å‰©ä½™ç®—åŠ› %d å·²ä¸è¶³ä»¥æ”¯ä»˜å½“å‰æ¨¡å‹çš„å•æ¬¡å¯¹è¯éœ€è¦æ¶ˆè€—çš„ç®—åŠ› %dï¼Œ[ç«‹å³è´­ä¹°](/member)ã€‚", userVo.Power, input.ChatModel.Power)
	}

	if userVo.ExpiredTime > 0 && userVo.ExpiredTime <= time.Now().Unix() {
		return errors.New("æ‚¨çš„è´¦å·å·²ç»è¿‡æœŸï¼Œè¯·è”ç³»ç®¡ç†å‘˜ï¼")
	}

	// æ£€æŸ¥ prompt é•¿åº¦æ˜¯å¦è¶…è¿‡äº†å½“å‰æ¨¡å‹å…è®¸çš„æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦
	promptTokens, _ := utils.CalcTokens(input.Prompt, input.ChatModel.Value)
	if promptTokens > input.ChatModel.MaxContext {

		return errors.New("å¯¹è¯å†…å®¹è¶…å‡ºäº†å½“å‰æ¨¡å‹å…è®¸çš„æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦ï¼")
	}

	var req = types.ApiRequest{
		Model:       input.ChatModel.Value,
		Stream:      input.Stream,
		Temperature: input.ChatModel.Temperature,
	}
	// å…¼å®¹ OpenAI æ¨¡å‹
	if strings.HasPrefix(input.ChatModel.Value, "o1-") ||
		strings.HasPrefix(input.ChatModel.Value, "o3-") ||
		strings.HasPrefix(input.ChatModel.Value, "gpt") {
		req.MaxCompletionTokens = input.ChatModel.MaxTokens
	} else {
		req.MaxTokens = input.ChatModel.MaxTokens
	}

	if len(input.Tools) > 0 && !strings.HasPrefix(input.ChatModel.Value, "o1-") {
		var items []model.Function
		res = h.DB.Where("enabled", true).Where("id IN ?", input.Tools).Find(&items)
		if res.Error == nil {
			var tools = make([]types.Tool, 0)
			for _, v := range items {
				var parameters map[string]interface{}
				err = utils.JsonDecode(v.Parameters, &parameters)
				if err != nil {
					continue
				}
				tool := types.Tool{
					Type: "function",
					Function: types.Function{
						Name:        v.Name,
						Description: v.Description,
						Parameters:  parameters,
					},
				}
				if v, ok := parameters["required"]; v == nil || !ok {
					tool.Function.Parameters["required"] = []string{}
				}
				tools = append(tools, tool)
			}

			if len(tools) > 0 {
				req.Tools = tools
				req.ToolChoice = "auto"
			}
		}
	}

	// åŠ è½½èŠå¤©ä¸Šä¸‹æ–‡
	chatCtx := make([]interface{}, 0)
	messages := make([]interface{}, 0)
	if h.App.SysConfig.EnableContext {
		if h.ChatContexts.Has(input.ChatId) {
			messages = h.ChatContexts.Get(input.ChatId)
		} else {
			_ = utils.JsonDecode(input.ChatRole.Context, &messages)
			if h.App.SysConfig.ContextDeep > 0 {
				var historyMessages []model.ChatMessage
				dbSession := h.DB.Session(&gorm.Session{}).Where("chat_id", input.ChatId)
				if input.LastMsgId > 0 { // é‡æ–°ç”Ÿæˆé€»è¾‘
					dbSession = dbSession.Where("id < ?", input.LastMsgId)
				}
				err = dbSession.Limit(h.App.SysConfig.ContextDeep).Order("id DESC").Find(&historyMessages).Error
				if err == nil {
					for i := len(historyMessages) - 1; i >= 0; i-- {
						msg := historyMessages[i]
						ms := types.Message{Role: "user", Content: msg.Content}
						if msg.Type == types.ReplyMsg {
							ms.Role = "assistant"
						}
						chatCtx = append(chatCtx, ms)
					}
				}
			}
		}

		// è®¡ç®—å½“å‰è¯·æ±‚çš„ token æ€»é•¿åº¦ï¼Œç¡®ä¿ä¸ä¼šè¶…å‡ºæœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦
		// MaxContextLength = Response + Tool + Prompt + Context
		tokens := req.MaxTokens // æœ€å¤§å“åº”é•¿åº¦
		tks, _ := utils.CalcTokens(utils.JsonEncode(req.Tools), req.Model)
		tokens += tks + promptTokens

		for i := len(messages) - 1; i >= 0; i-- {
			v := messages[i]
			tks, _ = utils.CalcTokens(utils.JsonEncode(v), req.Model)
			// ä¸Šä¸‹æ–‡ token è¶…å‡ºäº†æ¨¡å‹çš„æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦
			if tokens+tks >= input.ChatModel.MaxContext {
				break
			}

			// ä¸Šä¸‹æ–‡çš„æ·±åº¦è¶…å‡ºäº†æ¨¡å‹çš„æœ€å¤§ä¸Šä¸‹æ–‡æ·±åº¦
			if len(chatCtx) >= h.App.SysConfig.ContextDeep {
				break
			}

			tokens += tks
			chatCtx = append(chatCtx, v)
		}

		logger.Debugf("èŠå¤©ä¸Šä¸‹æ–‡ï¼š%+v", chatCtx)
	}
	reqMgs := make([]any, 0)

	for i := len(chatCtx) - 1; i >= 0; i-- {
		reqMgs = append(reqMgs, chatCtx[i])
	}

	fileContents := make([]string, 0) // æ–‡ä»¶å†…å®¹
	var finalPrompt = input.Prompt
	imgList := make([]any, 0)
	for _, file := range input.Files {
		logger.Debugf("detected file: %+v", file.URL)
		// å¤„ç†å›¾ç‰‡
		if isImageURL(file.URL) {
			imgList = append(imgList, gin.H{
				"type": "image_url",
				"image_url": gin.H{
					"url": file.URL,
				},
			})
		} else {
			// å¦‚æœä¸æ˜¯é€†å‘æ¨¡å‹ï¼Œåˆ™æå–æ–‡ä»¶å†…å®¹
			modelValue := input.ChatModel.Value
			if !(strings.Contains(modelValue, "-all") || strings.HasPrefix(modelValue, "gpt-4-gizmo") || strings.HasPrefix(modelValue, "claude")) {
				content, err := utils.ReadFileContent(file.URL, h.App.Config.TikaHost)
				if err != nil {
					logger.Error("error with read file: ", err)
					continue
				} else {
					fileContents = append(fileContents, fmt.Sprintf("%s æ–‡ä»¶å†…å®¹ï¼š%s", file.Name, content))
				}
			}
		}
	}

	if len(fileContents) > 0 {
		finalPrompt = fmt.Sprintf("è¯·æ ¹æ®æä¾›çš„æ–‡ä»¶å†…å®¹ä¿¡æ¯å›ç­”é—®é¢˜(å…¶ä¸­Excel å·²è½¬æˆ HTML)ï¼š\n\n %s\n\n é—®é¢˜ï¼š%s", strings.Join(fileContents, "\n"), input.Prompt)
		tokens, _ := utils.CalcTokens(finalPrompt, req.Model)
		if tokens > input.ChatModel.MaxContext {
			return fmt.Errorf("æ–‡ä»¶çš„é•¿åº¦è¶…å‡ºæ¨¡å‹å…è®¸çš„æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œè¯·å‡å°‘æ–‡ä»¶å†…å®¹æ•°é‡æˆ–æ–‡ä»¶å¤§å°ã€‚")
		}
	} else {
		finalPrompt = input.Prompt
	}

	if len(imgList) > 0 {
		imgList = append(imgList, map[string]interface{}{
			"type": "text",
			"text": input.Prompt,
		})
		req.Messages = append(reqMgs, map[string]interface{}{
			"role":    "user",
			"content": imgList,
		})
	} else {
		req.Messages = append(reqMgs, map[string]interface{}{
			"role":    "user",
			"content": finalPrompt,
		})
	}

	logger.Debugf("è¯·æ±‚æ¶ˆæ¯: %+v", req.Messages)

	return h.sendOpenAiMessage(req, userVo, ctx, input, c)
}

// åˆ¤æ–­ä¸€ä¸ª URL æ˜¯å¦å›¾ç‰‡é“¾æ¥
func isImageURL(url string) bool {
	// æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„URL
	if !strings.HasPrefix(url, "http://") && !strings.HasPrefix(url, "https://") {
		return false
	}

	// æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
	ext := strings.ToLower(path.Ext(url))
	validImageExts := map[string]bool{
		".jpg":  true,
		".jpeg": true,
		".png":  true,
		".gif":  true,
		".bmp":  true,
		".webp": true,
		".svg":  true,
		".ico":  true,
	}

	if !validImageExts[ext] {
		return false
	}

	// å‘é€HEADè¯·æ±‚æ£€æŸ¥Content-Type
	client := &http.Client{
		Timeout: 5 * time.Second,
	}
	resp, err := client.Head(url)
	if err != nil {
		return false
	}
	defer resp.Body.Close()

	contentType := resp.Header.Get("Content-Type")
	return strings.HasPrefix(contentType, "image/")
}

// Tokens ç»Ÿè®¡ token æ•°é‡
func (h *ChatHandler) Tokens(c *gin.Context) {
	var data struct {
		Text   string `json:"text"`
		Model  string `json:"model"`
		ChatId string `json:"chat_id"`
	}
	if err := c.ShouldBindJSON(&data); err != nil {
		resp.ERROR(c, types.InvalidArgs)
		return
	}

	// å¦‚æœæ²¡æœ‰ä¼ å…¥ text å­—æ®µï¼Œåˆ™è¯´æ˜æ˜¯è·å–å½“å‰ reply æ€»çš„ token æ¶ˆè€—ï¼ˆå¸¦ä¸Šä¸‹æ–‡ï¼‰
	if data.Text == "" && data.ChatId != "" {
		var item model.ChatMessage
		userId, _ := c.Get(types.LoginUserID)
		res := h.DB.Where("user_id = ?", userId).Where("chat_id = ?", data.ChatId).Last(&item)
		if res.Error != nil {
			resp.ERROR(c, res.Error.Error())
			return
		}
		resp.SUCCESS(c, item.Tokens)
		return
	}

	tokens, err := utils.CalcTokens(data.Text, data.Model)
	if err != nil {
		resp.ERROR(c, err.Error())
		return
	}

	resp.SUCCESS(c, tokens)
}

func getTotalTokens(req types.ApiRequest) int {
	encode := utils.JsonEncode(req.Messages)
	var items []map[string]interface{}
	err := utils.JsonDecode(encode, &items)
	if err != nil {
		return 0
	}
	tokens := 0
	for _, item := range items {
		content, ok := item["content"]
		if ok && !utils.IsEmptyValue(content) {
			t, err := utils.CalcTokens(utils.InterfaceToString(content), req.Model)
			if err == nil {
				tokens += t
			}
		}
	}
	return tokens
}

// StopGenerate åœæ­¢ç”Ÿæˆ
func (h *ChatHandler) StopGenerate(c *gin.Context) {
	sessionId := c.Query("session_id")
	if h.ReqCancelFunc.Has(sessionId) {
		h.ReqCancelFunc.Get(sessionId)()
		h.ReqCancelFunc.Delete(sessionId)
	}
	resp.SUCCESS(c, types.OkMsg)
}

// å‘é€è¯·æ±‚åˆ° OpenAI æœåŠ¡å™¨
// useOwnApiKey: æ˜¯å¦ä½¿ç”¨äº†ç”¨æˆ·è‡ªå·±çš„ API KEY
func (h *ChatHandler) doRequest(ctx context.Context, req types.ApiRequest, input ChatInput, apiKey *model.ApiKey) (*http.Response, error) {
	// if the chat model bind a KEY, use it directly
	if input.ChatModel.KeyId > 0 {
		h.DB.Where("id", input.ChatModel.KeyId).Find(apiKey)
	} else { // use the last unused key
		h.DB.Where("type", "chat").Where("enabled", true).Order("last_used_at ASC").First(apiKey)
	}

	if apiKey.Id == 0 {
		return nil, errors.New("no available key, please import key")
	}

	// ONLY allow apiURL in blank list
	err := h.licenseService.IsValidApiURL(apiKey.ApiURL)
	if err != nil {
		return nil, err
	}
	logger.Debugf("å¯¹è¯è¯·æ±‚æ¶ˆæ¯ä½“ï¼š%+v", req)
	var apiURL string
	p, _ := url.Parse(apiKey.ApiURL)
	// å¦‚æœè®¾ç½®çš„æ˜¯ BASE_URL æ²¡æœ‰è·¯å¾„ï¼Œåˆ™æ·»åŠ  /v1/chat/completions
	if p.Path == "" {
		apiURL = fmt.Sprintf("%s/v1/chat/completions", apiKey.ApiURL)
	} else {
		apiURL = apiKey.ApiURL
	}
	// åˆ›å»º HttpClient è¯·æ±‚å¯¹è±¡
	var client *http.Client
	requestBody, err := json.Marshal(req)
	if err != nil {
		return nil, err
	}
	request, err := http.NewRequest(http.MethodPost, apiURL, bytes.NewBuffer(requestBody))
	if err != nil {
		return nil, err
	}

	request = request.WithContext(ctx)
	request.Header.Set("Content-Type", "application/json")
	if len(apiKey.ProxyURL) > 5 { // ä½¿ç”¨ä»£ç†
		proxy, _ := url.Parse(apiKey.ProxyURL)
		client = &http.Client{
			Transport: &http.Transport{
				Proxy: http.ProxyURL(proxy),
			},
		}
	} else {
		client = http.DefaultClient
	}
	logger.Infof("Sending %s request, API KEY:%s, PROXY: %s, Model: %s", apiKey.ApiURL, apiURL, apiKey.ProxyURL, req.Model)
	request.Header.Set("Authorization", fmt.Sprintf("Bearer %s", apiKey.Value))
	// æ›´æ–°API KEY æœ€åä½¿ç”¨æ—¶é—´
	h.DB.Model(&model.ApiKey{}).Where("id", apiKey.Id).UpdateColumn("last_used_at", time.Now().Unix())
	return client.Do(request)
}

// æ‰£å‡ç”¨æˆ·ç®—åŠ›
func (h *ChatHandler) subUserPower(userVo vo.User, input ChatInput, promptTokens int, replyTokens int) {
	power := 1
	if input.ChatModel.Power > 0 {
		power = input.ChatModel.Power
	}

	err := h.userService.DecreasePower(userVo.Id, power, model.PowerLog{
		Type:   types.PowerConsume,
		Model:  input.ChatModel.Value,
		Remark: fmt.Sprintf("æ¨¡å‹åç§°ï¼š%s, æé—®é•¿åº¦ï¼š%dï¼Œå›å¤é•¿åº¦ï¼š%d", input.ChatModel.Name, promptTokens, replyTokens),
	})
	if err != nil {
		logger.Error(err)
	}
}

func (h *ChatHandler) saveChatHistory(
	req types.ApiRequest,
	usage Usage,
	message types.Message,
	input ChatInput,
	userVo vo.User,
	promptCreatedAt time.Time,
	replyCreatedAt time.Time) {

	// æ›´æ–°ä¸Šä¸‹æ–‡æ¶ˆæ¯
	if h.App.SysConfig.EnableContext {
		chatCtx := req.Messages            // æé—®æ¶ˆæ¯
		chatCtx = append(chatCtx, message) // å›å¤æ¶ˆæ¯
		h.ChatContexts.Put(input.ChatId, chatCtx)
	}

	// è¿½åŠ èŠå¤©è®°å½•
	// for prompt
	var promptTokens, replyTokens, totalTokens int
	if usage.PromptTokens > 0 {
		promptTokens = usage.PromptTokens
	} else {
		promptTokens, _ = utils.CalcTokens(usage.Content, req.Model)
	}

	historyUserMsg := model.ChatMessage{
		UserId: userVo.Id,
		ChatId: input.ChatId,
		RoleId: input.RoleId,
		Type:   types.PromptMsg,
		Icon:   userVo.Avatar,
		Content: utils.JsonEncode(vo.MsgContent{
			Text:  usage.Prompt,
			Files: input.Files,
		}),
		Tokens:      promptTokens,
		TotalTokens: promptTokens,
		UseContext:  true,
		Model:       req.Model,
	}
	historyUserMsg.CreatedAt = promptCreatedAt
	historyUserMsg.UpdatedAt = promptCreatedAt
	err := h.DB.Save(&historyUserMsg).Error
	if err != nil {
		logger.Error("failed to save prompt history message: ", err)
	}

	// for reply
	// è®¡ç®—æœ¬æ¬¡å¯¹è¯æ¶ˆè€—çš„æ€» token æ•°é‡
	if usage.CompletionTokens > 0 {
		replyTokens = usage.CompletionTokens
		totalTokens = usage.TotalTokens
	} else {
		replyTokens, _ = utils.CalcTokens(message.Content, req.Model)
		totalTokens = replyTokens + getTotalTokens(req)
	}
	historyReplyMsg := model.ChatMessage{
		UserId: userVo.Id,
		ChatId: input.ChatId,
		RoleId: input.RoleId,
		Type:   types.ReplyMsg,
		Icon:   input.ChatRole.Icon,
		Content: utils.JsonEncode(vo.MsgContent{
			Text:  message.Content,
			Files: input.Files,
		}),
		Tokens:      replyTokens,
		TotalTokens: totalTokens,
		UseContext:  true,
		Model:       req.Model,
	}
	historyReplyMsg.CreatedAt = replyCreatedAt
	historyReplyMsg.UpdatedAt = replyCreatedAt
	err = h.DB.Create(&historyReplyMsg).Error
	if err != nil {
		logger.Error("failed to save reply history message: ", err)
	}

	// æ›´æ–°ç”¨æˆ·ç®—åŠ›
	if input.ChatModel.Power > 0 {
		h.subUserPower(userVo, input, promptTokens, replyTokens)
	}
	// ä¿å­˜å½“å‰ä¼šè¯
	var chatItem model.ChatItem
	err = h.DB.Where("chat_id = ?", input.ChatId).First(&chatItem).Error
	if err != nil {
		chatItem.ChatId = input.ChatId
		chatItem.UserId = userVo.Id
		chatItem.RoleId = input.RoleId
		chatItem.ModelId = input.ModelId
		if utf8.RuneCountInString(usage.Prompt) > 30 {
			chatItem.Title = string([]rune(usage.Prompt)[:30]) + "..."
		} else {
			chatItem.Title = usage.Prompt
		}
		chatItem.Model = req.Model
		err = h.DB.Create(&chatItem).Error
		if err != nil {
			logger.Error("failed to save chat item: ", err)
		}
	}
}

// TextToSpeech æ–‡æœ¬ç”Ÿæˆè¯­éŸ³
func (h *ChatHandler) TextToSpeech(c *gin.Context) {
	var data struct {
		ModelId int    `json:"model_id"`
		Text    string `json:"text"`
	}
	if err := c.ShouldBindJSON(&data); err != nil {
		resp.ERROR(c, types.InvalidArgs)
		return
	}

	textHash := utils.Sha256(fmt.Sprintf("%d/%s", data.ModelId, data.Text))
	audioFile := fmt.Sprintf("%s/audio", h.App.Config.StaticDir)
	if _, err := os.Stat(audioFile); err != nil {
		resp.ERROR(c, err.Error())
		return
	}

	if err := os.MkdirAll(audioFile, 0755); err != nil {
		resp.ERROR(c, err.Error())
		return
	}
	audioFile = fmt.Sprintf("%s/%s.mp3", audioFile, textHash)
	if _, err := os.Stat(audioFile); err == nil {
		// è®¾ç½®å“åº”å¤´
		c.Header("Prompt-Type", "audio/mpeg")
		c.Header("Prompt-Disposition", "attachment; filename=speech.mp3")
		c.File(audioFile)
		return
	}

	// æŸ¥è¯¢æ¨¡å‹
	var chatModel model.ChatModel
	err := h.DB.Where("id", data.ModelId).First(&chatModel).Error
	if err != nil {
		resp.ERROR(c, "æ‰¾ä¸åˆ°è¯­éŸ³æ¨¡å‹")
		return
	}

	// è°ƒç”¨ DeepSeek çš„ API æ¥å£
	var apiKey model.ApiKey
	if chatModel.KeyId > 0 {
		h.DB.Where("id", chatModel.KeyId).First(&apiKey)
	}
	if apiKey.Id == 0 {
		h.DB.Where("type", "tts").Where("enabled", true).First(&apiKey)
	}
	if apiKey.Id == 0 {
		resp.ERROR(c, "no TTS API key, please import key")
		return
	}

	logger.Debugf("chatModel: %+v, apiKey: %+v", chatModel, apiKey)

	// è°ƒç”¨ openai tts api
	config := openai.DefaultConfig(apiKey.Value)
	config.BaseURL = apiKey.ApiURL + "/v1"
	client := openai.NewClientWithConfig(config)
	voice := openai.VoiceAlloy
	var options map[string]string
	err = utils.JsonDecode(chatModel.Options, &options)
	if err == nil {
		voice = openai.SpeechVoice(options["voice"])
	}
	req := openai.CreateSpeechRequest{
		Model: openai.SpeechModel(chatModel.Value),
		Input: data.Text,
		Voice: voice,
	}

	audioData, err := client.CreateSpeech(context.Background(), req)
	if err != nil {
		resp.ERROR(c, err.Error())
		return
	}

	// å…ˆå°†éŸ³é¢‘æ•°æ®è¯»å–åˆ°å†…å­˜
	audioBytes, err := io.ReadAll(audioData)
	if err != nil {
		resp.ERROR(c, err.Error())
		return
	}

	// ä¿å­˜åˆ°éŸ³é¢‘æ–‡ä»¶
	err = os.WriteFile(audioFile, audioBytes, 0644)
	if err != nil {
		logger.Error("failed to save audio file: ", err)
	}

	// è®¾ç½®å“åº”å¤´
	c.Header("Prompt-Type", "audio/mpeg")
	c.Header("Prompt-Disposition", "attachment; filename=speech.mp3")

	// ç›´æ¥å†™å…¥å®Œæ•´çš„éŸ³é¢‘æ•°æ®åˆ°å“åº”
	_, err = c.Writer.Write(audioBytes)
	if err != nil {
		logger.Error("å†™å…¥éŸ³é¢‘æ•°æ®åˆ°å“åº”å¤±è´¥:", err)
	}
}

// // OPenAI æ¶ˆæ¯å‘é€å®ç°
// func (h *ChatHandler) sendOpenAiMessage(
// 	req types.ApiRequest,
// 	userVo vo.User,
// 	ctx context.Context,
// 	session *types.ChatSession,
// 	role model.ChatRole,
// 	prompt string,
// 	c *gin.Context) error {
// 	promptCreatedAt := time.Now() // è®°å½•æé—®æ—¶é—´
// 	start := time.Now()
// 	var apiKey = model.ApiKey{}
// 	response, err := h.doRequest(ctx, req, session, &apiKey)
// 	logger.Info("HTTPè¯·æ±‚å®Œæˆï¼Œè€—æ—¶ï¼š", time.Since(start))
// 	if err != nil {
// 		if strings.Contains(err.Error(), "context canceled") {
// 			return fmt.Errorf("ç”¨æˆ·å–æ¶ˆäº†è¯·æ±‚ï¼š%s", prompt)
// 		} else if strings.Contains(err.Error(), "no available key") {
// 			return errors.New("æŠ±æ­‰ğŸ˜”ğŸ˜”ğŸ˜”ï¼Œç³»ç»Ÿå·²ç»æ²¡æœ‰å¯ç”¨çš„ API KEYï¼Œè¯·è”ç³»ç®¡ç†å‘˜ï¼")
// 		}
// 		return err
// 	} else {
// 		defer response.Body.Close()
// 	}

// 	if response.StatusCode != 200 {
// 		body, _ := io.ReadAll(response.Body)
// 		return fmt.Errorf("è¯·æ±‚ OpenAI API å¤±è´¥ï¼š%d, %v", response.StatusCode, string(body))
// 	}

// 	contentType := response.Header.Get("Prompt-Type")
// 	if strings.Contains(contentType, "text/event-stream") {
// 		replyCreatedAt := time.Now() // è®°å½•å›å¤æ—¶é—´
// 		// å¾ªç¯è¯»å– Chunk æ¶ˆæ¯
// 		var message = types.Message{Role: "assistant"}
// 		var contents = make([]string, 0)
// 		var function model.Function
// 		var toolCall = false
// 		var arguments = make([]string, 0)
// 		var reasoning = false

// 		pushMessage(c, ChatEventStart, "å¼€å§‹å“åº”")
// 		scanner := bufio.NewScanner(response.Body)
// 		for scanner.Scan() {
// 			line := scanner.Text()
// 			if !strings.Contains(line, "data:") || len(line) < 30 {
// 				continue
// 			}
// 			var responseBody = types.ApiResponse{}
// 			err = json.Unmarshal([]byte(line[6:]), &responseBody)
// 			if err != nil { // æ•°æ®è§£æå‡ºé”™
// 				return errors.New(line)
// 			}
// 			if len(responseBody.Choices) == 0 { // Fixed: å…¼å®¹ Azure API ç¬¬ä¸€ä¸ªè¾“å‡ºç©ºè¡Œ
// 				continue
// 			}
// 			if responseBody.Choices[0].Delta.Prompt == nil &&
// 				responseBody.Choices[0].Delta.ToolCalls == nil &&
// 				responseBody.Choices[0].Delta.ReasoningContent == "" {
// 				continue
// 			}

// 			if responseBody.Choices[0].FinishReason == "stop" && len(contents) == 0 {
// 				pushMessage(c, ChatEventError, "æŠ±æ­‰ğŸ˜”ğŸ˜”ğŸ˜”ï¼ŒAIåŠ©æ‰‹ç”±äºæœªçŸ¥åŸå› å·²ç»åœæ­¢è¾“å‡ºå†…å®¹ã€‚")
// 				break
// 			}

// 			var tool types.ToolCall
// 			if len(responseBody.Choices[0].Delta.ToolCalls) > 0 {
// 				tool = responseBody.Choices[0].Delta.ToolCalls[0]
// 				if toolCall && tool.Function.Name == "" {
// 					arguments = append(arguments, tool.Function.Arguments)
// 					continue
// 				}
// 			}

// 			// å…¼å®¹ Function Call
// 			fun := responseBody.Choices[0].Delta.FunctionCall
// 			if fun.Name != "" {
// 				tool = *new(types.ToolCall)
// 				tool.Function.Name = fun.Name
// 			} else if toolCall {
// 				arguments = append(arguments, fun.Arguments)
// 				continue
// 			}

// 			if !utils.IsEmptyValue(tool) {
// 				res := h.DB.Where("name = ?", tool.Function.Name).First(&function)
// 				if res.Error == nil {
// 					toolCall = true
// 					callMsg := fmt.Sprintf("æ­£åœ¨è°ƒç”¨å·¥å…· `%s` ä½œç­” ...\n\n", function.Label)
// 					pushMessage(c, ChatEventMessageDelta, map[string]interface{}{
// 						"type":    "text",
// 						"content": callMsg,
// 					})
// 					contents = append(contents, callMsg)
// 				}
// 				continue
// 			}

// 			if responseBody.Choices[0].FinishReason == "tool_calls" ||
// 				responseBody.Choices[0].FinishReason == "function_call" { // å‡½æ•°è°ƒç”¨å®Œæ¯•
// 				break
// 			}

// 			// output stopped
// 			if responseBody.Choices[0].FinishReason != "" {
// 				break // è¾“å‡ºå®Œæˆæˆ–è€…è¾“å‡ºä¸­æ–­äº†
// 			} else { // æ­£å¸¸è¾“å‡ºç»“æœ
// 				// å…¼å®¹æ€è€ƒè¿‡ç¨‹
// 				if responseBody.Choices[0].Delta.ReasoningContent != "" {
// 					reasoningContent := responseBody.Choices[0].Delta.ReasoningContent
// 					if !reasoning {
// 						reasoningContent = fmt.Sprintf("<think>%s", reasoningContent)
// 						reasoning = true
// 					}

// 					pushMessage(c, ChatEventMessageDelta, map[string]interface{}{
// 						"type":    "text",
// 						"content": reasoningContent,
// 					})
// 					contents = append(contents, reasoningContent)
// 				} else if responseBody.Choices[0].Delta.Prompt != "" {
// 					finalContent := responseBody.Choices[0].Delta.Prompt
// 					if reasoning {
// 						finalContent = fmt.Sprintf("</think>%s", responseBody.Choices[0].Delta.Prompt)
// 						reasoning = false
// 					}
// 					contents = append(contents, utils.InterfaceToString(finalContent))
// 					pushMessage(c, ChatEventMessageDelta, map[string]interface{}{
// 						"type":    "text",
// 						"content": finalContent,
// 					})
// 				}
// 			}
// 		} // end for

// 		if err := scanner.Err(); err != nil {
// 			if strings.Contains(err.Error(), "context canceled") {
// 				logger.Info("ç”¨æˆ·å–æ¶ˆäº†è¯·æ±‚ï¼š", prompt)
// 			} else {
// 				logger.Error("ä¿¡æ¯è¯»å–å‡ºé”™ï¼š", err)
// 			}
// 		}

// 		if toolCall { // è°ƒç”¨å‡½æ•°å®Œæˆä»»åŠ¡
// 			params := make(map[string]any)
// 			_ = utils.JsonDecode(strings.Join(arguments, ""), &params)
// 			logger.Debugf("å‡½æ•°åç§°: %s, å‡½æ•°å‚æ•°ï¼š%s", function.Name, params)
// 			params["user_id"] = userVo.Id
// 			var apiRes types.BizVo
// 			r, err := req2.C().R().SetHeader("Body-Type", "application/json").
// 				SetHeader("Authorization", function.Token).
// 				SetBody(params).Post(function.Action)
// 			errMsg := ""
// 			if err != nil {
// 				errMsg = err.Error()
// 			} else {
// 				all, _ := io.ReadAll(r.Body)
// 				err = json.Unmarshal(all, &apiRes)
// 				if err != nil {
// 					errMsg = err.Error()
// 				} else if apiRes.Code != types.Success {
// 					errMsg = apiRes.Message
// 				}
// 			}

// 			if errMsg != "" {
// 				errMsg = "è°ƒç”¨å‡½æ•°å·¥å…·å‡ºé”™ï¼š" + errMsg
// 				contents = append(contents, errMsg)
// 			} else {
// 				errMsg = utils.InterfaceToString(apiRes.Data)
// 				contents = append(contents, errMsg)
// 			}
// 			pushMessage(c, ChatEventMessageDelta, map[string]interface{}{
// 				"type":    "text",
// 				"content": errMsg,
// 			})
// 		}

// 		// æ¶ˆæ¯å‘é€æˆåŠŸ
// 		if len(contents) > 0 {
// 			usage := Usage{
// 				Prompt:           prompt,
// 				Prompt:          strings.Join(contents, ""),
// 				PromptTokens:     0,
// 				CompletionTokens: 0,
// 				TotalTokens:      0,
// 			}
// 			message.Prompt = usage.Prompt
// 			h.saveChatHistory(req, usage, message, session, role, userVo, promptCreatedAt, replyCreatedAt)
// 		}
// 	} else {
// 		var respVo OpenAIResVo
// 		body, err := io.ReadAll(response.Body)
// 		if err != nil {
// 			return fmt.Errorf("è¯»å–å“åº”å¤±è´¥ï¼š%v", body)
// 		}
// 		err = json.Unmarshal(body, &respVo)
// 		if err != nil {
// 			return fmt.Errorf("è§£æå“åº”å¤±è´¥ï¼š%v", body)
// 		}
// 		content := respVo.Choices[0].Message.Prompt
// 		if strings.HasPrefix(req.Model, "o1-") {
// 			content = fmt.Sprintf("AIæ€è€ƒç»“æŸï¼Œè€—æ—¶ï¼š%d ç§’ã€‚\n%s", time.Now().Unix()-session.Start, respVo.Choices[0].Message.Prompt)
// 		}
// 		pushMessage(c, ChatEventMessageDelta, map[string]interface{}{
// 			"type":    "text",
// 			"content": content,
// 		})
// 		respVo.Usage.Prompt = prompt
// 		respVo.Usage.Prompt = content
// 		h.saveChatHistory(req, respVo.Usage, respVo.Choices[0].Message, session, role, userVo, promptCreatedAt, time.Now())
// 	}

// 	return nil
// }
